{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a5d56e-1a44-4823-81e2-b20f008cb0fe",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Leverage AI Skill for comprehensive insights into your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3120c-c673-462e-9828-f06b44ac3eb0",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The AI Skill is a new experience in Microsoft Fabric that enables you to customize a generative AI expert on your data. Simply by selecting the relevant data sources in Fabric, you can create a Q&A chatbot that delivers insightful answers. This notebook will guide you on how to configure the AI Skill by providing additional context and details, in order to receive more comprehensive and contextually rich responses.\n",
    "\n",
    "To illustrate, if a user queries about the best-selling product for a specific year within a retail dataset, AI Skill can be configured to provide more than just the top product. For example, it can display the top three best-selling products for that year and compare them to top sellers from previous years. This additional context helps users identify trends, such as shifts in top-selling products over time and their performance relative to other products.\n",
    "\n",
    "This enriched Q&A experience can be achieved by integrating AI Skill with additional large language model (LLM) calls. The main steps include:\n",
    "\n",
    "- Generate Additional Questions with LLM: Start by passing the user's question to the LLM. Request the LLM to generate multiple (e.g., three) supplementary questions that can provide more context or gather additional information related to the original question. For instance, if the user's question is `What is the best-selling product in 2019?`, the LLM might generate questions like `What are the top three best-selling products in 2019?`, `What were the best-selling products in 2018?`, or `What are the all-time best-selling products?`.\n",
    "\n",
    "- Query AI Skill with All Questions: Submit both the original user's question and the additional questions generated by the LLM to the AI Skill. AI Skill will then query the dataset for each question separately, retrieving the relevant data for each question.\n",
    "\n",
    "- Formulate a Comprehensive Answer with LLM: Use the results obtained from the AI Skill and pass this information to another LLM call. Instruct the LLM to craft a detailed response to the original question, incorporating the additional data provided.\n",
    "\n",
    "By integrating AI Skill and LLMs, you can develop an enhanced solution that leverages  AI Skill's ability alongside the generality of LLMs to generate and execute SQL queries from natural language.\n",
    "\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AISkill/University_QnA.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "\n",
    "The main steps in this notebook are:\n",
    "\n",
    "1. Set up the lakehouse and add the relevant tables to the lakehouse\n",
    "2. Create and publish AI Skill\n",
    "3. Generate additional queries\n",
    "4. Call the AI Skill function\n",
    "5. Generate the conceptually rich final answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9aaca-16d9-49a8-b0dc-db8d9bfa037f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. To leverage Azure OpenAI in Fabric, you would require a [Fabric capacity (F64 or higher)](https://aka.ms/fabric/copilot-capacity).\n",
    "2. Read about AI Skill specific requirements [here](https://aka.ms/fabric/ai-skill-prerequisites)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2869cf-c63b-4752-a607-712dbe8fa671",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 1: Set up the lakehouse and add the relevant tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a638a-602b-461f-940e-05394b3dd8b3",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Create a lakehouse and then open a Fabric notebook. Attach the lakehouse to the notebook, and run the following code to add all tables to your lakehouse. Note that you will be using the AdventureWorks dataset which includes retail data with tables for sales, products, customers, promotions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06faec1b-3ece-4107-ab4d-66802a009010",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:41.3415067Z",
       "execution_start_time": "2024-09-16T15:37:59.3069559Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "0a691c5f-9212-438a-b568-4088b88ab4a7",
       "queued_time": "2024-09-16T15:37:46.7976696Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": "2024-09-16T15:37:46.9976883Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0d420d60f44e6182290bb7eafcd6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:45:46.6146979Z",
       "execution_start_time": "2024-09-16T15:45:46.197395Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "564d3d85-28f8-4bc0-8a93-62079752bd15",
       "queued_time": "2024-09-16T15:39:13.419984Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 21,
       "statement_ids": [
        21
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 21, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "base = \"https://synapseaisolutionsa.blob.core.windows.net/public/AdventureWorks\"\n",
    "\n",
    "# load list of tables\n",
    "df_tables = pd.read_csv(f\"{base}/adventureworks.csv\", names=[\"table\"])\n",
    "\n",
    "for table in (pbar := tqdm(df_tables['table'].values)):\n",
    "    pbar.set_description(f\"Uploading {table} to lakehouse\")\n",
    "\n",
    "    # download\n",
    "    df = pd.read_parquet(f\"{base}/{table}.parquet\")\n",
    "\n",
    "    # save as lakehouse table\n",
    "    spark.createDataFrame(df).write.mode('overwrite').saveAsTable(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43080d34-3a15-4057-a6a5-3f8312a07305",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 2: Create and publish an AI Skill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f841d-4034-449e-85c2-9fe30a87ba33",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Follow the steps below to create an AI Skill based on the lakehouse you created in Step 1.\n",
    "\n",
    "1. Go to the Data Science experience and select AI Skill.\n",
    "\n",
    "2. Enter a name to create an AI Skill.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AISkill/create-ai-skill.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "3. Select the lakehouse you created above and select Connect.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AISkill/change-datasource.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "4. You must then select the tables for which you want the AI Skill to have available access. From the left panel, select the tables **dimproduct**, **dimpromotion**, **factinternetsales** as these are the only tables needed for this notebook.\n",
    "\n",
    "5. To improve the quality of the query generated by the AI Skill, provide the following the instructions as parts of the `Notes to model`.\n",
    "\n",
    "    - When answering about a product, make sure to include the Product Name in `dimproduct` in the answer. \n",
    "    - Best selling product should be determined by sales volume, not sales amount. \n",
    "    - If you answer questions about quantities, make sure to include the quantity. \n",
    "    - If the user asks about promotion, note that `No Discount` appearing in `dimpromotion` is not actually a promotion. Always filter out the `No Discount` if user asks about promotion. \n",
    "    - If the question is generic and involves no finite entities such as \"top 5\", use a reasonable number less than 10, so that answer is not too large.\n",
    "\n",
    "6. Validate the performance of the AI Skill by asking the following questions and reviewing both the final answers and the generated SQL queries used to retrieve them.\n",
    "\n",
    "7. Click on the publish button to publish the AI Skill. Once published, navigate to the Settings, then click on Publishing to copy the provided URL to the cell below. You will use the URL to query the AI skill by making calls to the AI skill API in a this notebook. Learn more about how to use AI Skill programmatically [here](https://aka.ms/fabric/use-aiskill-programmatically).\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AISkill/ai-select-publish.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AISkill/initial-ai-skill-settings.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AISkill/fabric-notebook-ai-skill-published-url-value.png\" width=\"70%\" height=\"70%\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3f421-e66e-40b0-af98-3cfef14384dd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:42.1001368Z",
       "execution_start_time": "2024-09-16T15:43:41.7402434Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "5aacc9d9-ec9b-4901-8f24-d35708f15c9d",
       "queued_time": "2024-09-16T15:37:46.7984786Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 4, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AI Skill URL\n",
    "aiskill_url = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586c0b2-83d7-48c0-bd64-fb3c5e51833e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##  Step 3: Generate additional queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37d1db-15ad-4812-a14b-af56a70cf6a0",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In this section, you'll explore how to transform your initial question into several related questions. By rephrasing the original question in different ways, you can gather more comprehensive information and provide a deeper understanding of the topic at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3fc5db-2183-4450-9b6b-53a126647fcc",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Set up the function to generate additional queries\n",
    "\n",
    "Below is a sample prompt that demonstrates how to generate multiple relevant questions based on the your initial question.\n",
    "\n",
    "In the following function, you will see how to call a specific LLM model from OpenAI. The parameters—deployment ID, messages, temperature, and seed—are part of the experimental setup.\n",
    "\n",
    "In this case, the prompt and question are passed directly into the messages, the temperature is set to 0, the seed is fixed, and the deployment ID is set to one of the supported models. For information on switching models, please refer to [Fabric AI Services](https://aka.ms/fabric/ai-services-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd133275-9ea4-4535-809f-f7fb3d4dbce4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:42.8573458Z",
       "execution_start_time": "2024-09-16T15:43:42.4877108Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "fa3c5f96-7ed1-421e-889e-27dcc00b1f46",
       "queued_time": "2024-09-16T15:37:46.799168Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 5,
       "statement_ids": [
        5
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 5, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_extract_questions = \"\"\"You are a helpful analyst. You are given a user query, using the query create 3 relevant questions that will give more information around the *question being asked*. \n",
    "For example: If the question is, what is the top selling product in 2019? The rephrased questions could be: \n",
    "what were the top selling 3 products in 2019? what were the top 3 products sold in 2018? or what were the top 3 best-selling products across all years? \n",
    "Note that these questions will be independently used to query a SQL table.  Don't enumerate the questions and put each question in a new line.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5aad5f-fef5-4b03-aeb8-daf8622b9876",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:44.3000298Z",
       "execution_start_time": "2024-09-16T15:43:43.250771Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "69abd512-6c20-433b-924d-cb6e61448958",
       "queued_time": "2024-09-16T15:37:46.8003513Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 6,
       "statement_ids": [
        6
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 6, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Given a user question, generates 3 more questions that will be used to obtain more context about the original question\n",
    "def openAI_service_multiple_questions(query):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id='gpt-4-32k',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt_extract_questions},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        seed=40,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22cc34-f688-4fd9-aa07-99a2940d118f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Provide user's specific question\n",
    "\n",
    "You can now provide your own prompt, which will be fed as input to the `openAI_service_multiple_questions` function defined above to generate relevant questions. This allows you to customize the process and obtain more targeted information from the AI Skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d57699-2178-482f-a267-91750ce0abbc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:47.6490763Z",
       "execution_start_time": "2024-09-16T15:43:44.7119783Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "c668f32f-b93d-411d-99c1-c42e6fb8e50b",
       "queued_time": "2024-09-16T15:37:46.8038324Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 7,
       "statement_ids": [
        7
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 7, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What were the top 3 selling products in 2013?\n",
      "What was the top selling product in 2012?\n",
      "What were the top selling products across all years?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the top selling product in 2013?\"\n",
    "\n",
    "response = openAI_service_multiple_questions(query)\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5aa8b-d1c2-404e-baf5-f4d99c83b844",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Once you have seen the generated questions by the `openAI_service_multiple_questions` function, you can break it into separate lines which helps to extract each question separately for easier processing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f8a72-0852-4013-a4c5-a307328915c8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:48.435573Z",
       "execution_start_time": "2024-09-16T15:43:48.0696432Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "1527bd59-f437-4600-bd8b-c449ebb3ea99",
       "queued_time": "2024-09-16T15:37:46.8085716Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 8,
       "statement_ids": [
        8
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 8, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What were the top 3 selling products in 2013?', 'What was the top selling product in 2012?', 'What were the top selling products across all years?']\n"
     ]
    }
   ],
   "source": [
    "questions = answer.split(\"\\n\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2a6a3-8185-4451-b463-d4a639e69f81",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 4: Call the AI Skill function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4491c3-ba3f-4322-a76c-46a383b7037a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Once you have generated relevant questions, you move to next step to define the function `aiSkill` which would take three inputs\n",
    "\n",
    "- `context`: the notes for the model in the AI Skill\n",
    "- `question`: user's question\n",
    "- `aiskill_url`: the URL of the published AI Skill\n",
    "\n",
    "in order to generate the SQL query based on these inputs. It then outputs the answer in a JSON format within the `response`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7609a-0e67-4568-8298-73279ce3f7b1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:50.1086923Z",
       "execution_start_time": "2024-09-16T15:43:48.8164914Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "31240fdf-cda1-4b8d-9ef0-7a32d1a4a449",
       "queued_time": "2024-09-16T15:37:46.8167825Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 9,
       "statement_ids": [
        9
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 9, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from synapse.ml.mlflow import get_mlflow_env_config\n",
    "from tenacity import retry, stop_after_attempt\n",
    "import requests\n",
    "import json\n",
    "\n",
    "@retry(stop=stop_after_attempt(3))  # Retry up to 3 times\n",
    "def aiSkill(context, question, aiskill_url):\n",
    "\n",
    "    configs = get_mlflow_env_config()   \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {configs.driver_aad_token}\",\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\"\n",
    "    }\n",
    "\n",
    "    text = {\n",
    "        'userQuestion': question, \n",
    "        'modelBehavior' : {\n",
    "            'enableBlockAdditionalContextByLength': False,\n",
    "        },\n",
    "        'additionalContext': context # notes to the model\n",
    "    }\n",
    "\n",
    "    response = requests.post(aiskill_url, headers=headers, data = json.dumps(text))\n",
    "\n",
    "    response = json.loads(response.content)\n",
    "\n",
    "    # If the AISkill didn't generate a good SQL query, it will throw an error\n",
    "    if \"ResultRows\" not in response.keys():\n",
    "        raise ValueError(response[\"message\"])\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57a64e-a112-42d3-b830-82b5f1566e23",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In the following, you'll provide relevant context or notes to the AI Skill. Note that this additional information - which is usually provided by the subject matter expert who has good knowledge of the data - helps the AI Skill determine the appropriate columns to use and generate accurate and relevant outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3dcea-a04e-44e9-8ad8-0814c1941826",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:50.9333907Z",
       "execution_start_time": "2024-09-16T15:43:50.5400706Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7989ea4f-00af-4e84-9ef8-0dc1ececacc1",
       "queued_time": "2024-09-16T15:37:46.8175302Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 10,
       "statement_ids": [
        10
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 10, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes = \"\"\" \\\n",
    "- When answering about a product, make sure to include the Product Name in dimproduct in the answer. \n",
    "- Best selling product should be determined by sales volume, not sales amount. \n",
    "- If you answer questions about quantities, make sure to include the quantity. \n",
    "- If the user asks about promotion, note that \"No Discount\" appearing in dimpromotion is not actually a promotion. Always filter out the \"No Discount\" if user asks about promotion. \n",
    "- If the question is generic and involves no finite entities such as \"top 5\", use a reasonable number less than 10, so that answer is not too large.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf3bd3-7384-470d-ad1d-932cb2d37db0",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Consolidate all outputs from the AI Skill by combining the results generated for each rephrased question into a single, unified set of answers. This ensures that you have a comprehensive view of all the responses and can analyze or utilize them collectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99156ed-4f62-4efb-91a7-8dcf75319760",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:43:51.7221112Z",
       "execution_start_time": "2024-09-16T15:43:51.3473392Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "72ea5c84-5056-4b44-885d-3a9132cd35ef",
       "queued_time": "2024-09-16T15:37:46.8190214Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 11,
       "statement_ids": [
        11
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 11, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run a loop over the generated questions and get an answer from AI Skill\n",
    "def get_context_from_aiSkill(questions):\n",
    "    ai_skill_response = []\n",
    "    ai_skill_sql = []\n",
    "    for question in questions:\n",
    "        response = aiSkill(notes, question, aiskill_url)\n",
    "        ai_skill_response.append(f\"headers: {response['ResultHeaders']}, rows: {response['ResultRows']}\")\n",
    "        ai_skill_sql.append(response['executedSQL'])\n",
    "    return ai_skill_response, ai_skill_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7378b-fbfe-455d-8784-9af991e2b11e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:33.5501549Z",
       "execution_start_time": "2024-09-16T15:43:52.1099456Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7da0dbd7-8c4d-4ab8-83d6-7c4b08acb9da",
       "queued_time": "2024-09-16T15:37:46.8204463Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 12,
       "statement_ids": [
        12
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 12, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions.append(query)\n",
    "ai_skill_response, ai_skill_sql = get_context_from_aiSkill(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d180099-5a85-4249-8a5d-85337f3190bb",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You can review the SQL query generated for the each of the rephrased question. This allows you to verify and understand the SQL code created by the AI Skill in response to each specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b1b17-decd-4d7b-af18-a5813ccf9416",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:34.3057584Z",
       "execution_start_time": "2024-09-16T15:44:33.9324561Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "3a91327e-ef24-46cc-96ae-a80306d7bc1b",
       "queued_time": "2024-09-16T15:37:46.8246923Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 13,
       "statement_ids": [
        13
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 13, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adjust Pandas display options to prevent truncation of long strings\n",
    "pd.set_option('display.max_colwidth', None)  # Set to 'None' to display all contents without truncation\n",
    "\n",
    "def display_ai_skill_data(questions, ai_skill_sql, ai_skill_response):\n",
    "    \"\"\"\n",
    "    This function takes questions, AI Skill SQL queries, and AI Skill responses, and \n",
    "    displays them in a table with three columns: 'Question', 'SQL Query', and 'AI Skill Response'.\n",
    "    \n",
    "    Args:\n",
    "    questions (list): List of questions.\n",
    "    ai_skill_sql (list): List of SQL queries generated by AI Skill.\n",
    "    ai_skill_response (list): List of responses generated by AI Skill.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A pandas DataFrame containing the questions, SQL queries, and responses.\n",
    "    \"\"\"\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Question': questions,\n",
    "        'SQL Query': ai_skill_sql,\n",
    "        'AI Skill Response': ai_skill_response\n",
    "    })\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29130c5a-3d62-4a79-96e8-21c69f89dca5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:35.0925761Z",
       "execution_start_time": "2024-09-16T15:44:34.7161532Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "9758fb9f-d78d-4049-8523-2e7768493028",
       "queued_time": "2024-09-16T15:37:46.8279352Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 14,
       "statement_ids": [
        14
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 14, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>SQL Query</th>\n",
       "      <th>AI Skill Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What were the top 3 selling products in 2013?</td>\n",
       "      <td>SELECT TOP 3 \\n    dp.EnglishProductName AS ProductName,\\n    SUM(fis.OrderQuantity) AS TotalQuantity\\nFROM \\n    dbo.factinternetsales fis\\nJOIN \\n    dbo.dimproduct dp ON fis.ProductKey = dp.ProductKey\\nWHERE \\n    YEAR(fis.OrderDate) = 2013\\nGROUP BY \\n    dp.EnglishProductName\\nORDER BY \\n    TotalQuantity DESC;</td>\n",
       "      <td>headers: ['ProductName', 'TotalQuantity'], rows: [['Water Bottle - 30 oz.', 4080], ['Patch Kit/8 Patches', 3026], ['Mountain Tire Tube', 2926]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the top selling product in 2012?</td>\n",
       "      <td>SELECT TOP 1 dp.EnglishProductName AS TopSellingProduct\\nFROM dbo.factinternetsales fis\\nJOIN dbo.dimproduct dp ON fis.ProductKey = dp.ProductKey\\nWHERE YEAR(fis.OrderDate) = 2012\\nGROUP BY dp.EnglishProductName\\nORDER BY SUM(fis.OrderQuantity) DESC;</td>\n",
       "      <td>headers: ['TopSellingProduct'], rows: [['Mountain-200 Black, 46']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What were the top selling products across all years?</td>\n",
       "      <td>SELECT TOP 5 dp.EnglishProductName AS TopSellingProduct, SUM(fis.OrderQuantity) AS TotalQuantity\\nFROM dbo.factinternetsales fis\\nJOIN dbo.dimproduct dp ON fis.ProductKey = dp.ProductKey\\nGROUP BY dp.EnglishProductName\\nORDER BY TotalQuantity DESC;</td>\n",
       "      <td>headers: ['TopSellingProduct', 'TotalQuantity'], rows: [['Water Bottle - 30 oz.', 4244], ['Patch Kit/8 Patches', 3191], ['Mountain Tire Tube', 3095], ['Road Tire Tube', 2376], ['Sport-100 Helmet, Red', 2230]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "0         What were the top 3 selling products in 2013?   \n",
       "1             What was the top selling product in 2012?   \n",
       "2  What were the top selling products across all years?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                       SQL Query  \\\n",
       "0  SELECT TOP 3 \\n    dp.EnglishProductName AS ProductName,\\n    SUM(fis.OrderQuantity) AS TotalQuantity\\nFROM \\n    dbo.factinternetsales fis\\nJOIN \\n    dbo.dimproduct dp ON fis.ProductKey = dp.ProductKey\\nWHERE \\n    YEAR(fis.OrderDate) = 2013\\nGROUP BY \\n    dp.EnglishProductName\\nORDER BY \\n    TotalQuantity DESC;   \n",
       "1                                                                     SELECT TOP 1 dp.EnglishProductName AS TopSellingProduct\\nFROM dbo.factinternetsales fis\\nJOIN dbo.dimproduct dp ON fis.ProductKey = dp.ProductKey\\nWHERE YEAR(fis.OrderDate) = 2012\\nGROUP BY dp.EnglishProductName\\nORDER BY SUM(fis.OrderQuantity) DESC;   \n",
       "2                                                                       SELECT TOP 5 dp.EnglishProductName AS TopSellingProduct, SUM(fis.OrderQuantity) AS TotalQuantity\\nFROM dbo.factinternetsales fis\\nJOIN dbo.dimproduct dp ON fis.ProductKey = dp.ProductKey\\nGROUP BY dp.EnglishProductName\\nORDER BY TotalQuantity DESC;   \n",
       "\n",
       "                                                                                                                                                                                                  AI Skill Response  \n",
       "0                                                                   headers: ['ProductName', 'TotalQuantity'], rows: [['Water Bottle - 30 oz.', 4080], ['Patch Kit/8 Patches', 3026], ['Mountain Tire Tube', 2926]]  \n",
       "1                                                                                                                                                headers: ['TopSellingProduct'], rows: [['Mountain-200 Black, 46']]  \n",
       "2  headers: ['TopSellingProduct', 'TotalQuantity'], rows: [['Water Bottle - 30 oz.', 4244], ['Patch Kit/8 Patches', 3191], ['Mountain Tire Tube', 3095], ['Road Tire Tube', 2376], ['Sport-100 Helmet, Red', 2230]]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\n",
    "    questions[0],\n",
    "    questions[1],\n",
    "    questions[2]\n",
    "]\n",
    "\n",
    "ai_skill_sql = [\n",
    "    ai_skill_sql[0],\n",
    "    ai_skill_sql[1],\n",
    "    ai_skill_sql[2]\n",
    "]\n",
    "\n",
    "ai_skill_response = [\n",
    "    ai_skill_response[0],\n",
    "    ai_skill_response[1],\n",
    "    ai_skill_response[2]\n",
    "]\n",
    "\n",
    "# Call the function and display the data\n",
    "display_ai_skill_data(questions, ai_skill_sql, ai_skill_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68465a0f-012d-4c7e-bab5-d9eb787c8b7f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In the following, you will integrate the questions and answers from the AI Skill into the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61c9f1-a29b-4ee2-aaab-2536fb78c9d6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:35.8611672Z",
       "execution_start_time": "2024-09-16T15:44:35.4909183Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "f3e5a3ff-181a-45b2-8491-3bb1a912b911",
       "queued_time": "2024-09-16T15:37:46.8328841Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 15,
       "statement_ids": [
        15
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 15, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_context_to_answer_with_llm(query, rephrased_query, ai_skill_response):\n",
    "    context = \"\"\n",
    "    for index, question in enumerate(questions):\n",
    "        context += f\"rephrased question: {question} \\n\" + f\"header and rows of the table: {ai_skill_response[index]}\\n\" \n",
    "\n",
    "    context += f\"user query: {query}\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb614db1-1360-43e3-b2fe-aaceb7e6a17b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:36.5817883Z",
       "execution_start_time": "2024-09-16T15:44:36.2450496Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "0280311e-c3d5-4f75-bc1b-a37345d81c66",
       "queued_time": "2024-09-16T15:37:46.8337286Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 16,
       "statement_ids": [
        16
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 16, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = get_context_to_answer_with_llm(query, questions, ai_skill_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904216b2-d402-4b9c-9c4f-9085951b80bb",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 5: Generate conceptually rich answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6ddb9-6a3e-49a0-b5d0-06f89c0e2f5f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Consolidating the initial question, all additional questions, and the AI Skill response into the final LLM-generated answer. This process results in a cohesive, comprehensive answer produced by LLM, integrating all relevant information into a final, unified response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ccb5a-91bd-4c40-acfa-bdd226a55bee",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:37.3716137Z",
       "execution_start_time": "2024-09-16T15:44:37.0118669Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "aef901c2-a771-4472-98fe-1b1e211049aa",
       "queued_time": "2024-09-16T15:37:46.8358065Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 17,
       "statement_ids": [
        17
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 17, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_final_answer = \"\"\"You are an expert analyst. Given a user query, rephrased query asking more details, and the relevant context that is from an output of a SQL \n",
    "table presented as headers and corresponding rows, answer the user question with details. \n",
    "Formulate your response to directly answer the original user query, while adding details with the answers to the rephrased queries. \n",
    "Do not mention things like 'Based on the data provided' or anything about the data, just answer the user question.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b49233-ccd9-4b03-a1e2-ff6cb30e3fab",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:44:44.9726751Z",
       "execution_start_time": "2024-09-16T15:44:37.7607599Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "2a1b6f1d-51e8-468d-a39c-d36c8c55b255",
       "queued_time": "2024-09-16T15:37:46.840784Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 18,
       "statement_ids": [
        18
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 18, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top selling products in 2013 were the Water Bottle - 30 oz., Patch Kit/8 Patches, and Mountain Tire Tube, with total quantities of 4080, 3026, and 2926 respectively. In 2012, the top selling product was the Mountain-200 Black, 46. \n",
      "\n",
      "When we look at the top selling products across all years, the Water Bottle - 30 oz. leads the pack with a total quantity of 4244. Following closely are the Patch Kit/8 Patches and Mountain Tire Tube with total quantities of 3191 and 3095 respectively. Other notable top sellers include the Road Tire Tube and Sport-100 Helmet, Red, with total quantities of 2376 and 2230 respectively.\n",
      "\n",
      "In conclusion, the top selling product in 2013 was the Water Bottle - 30 oz. with a total quantity of 4080.\n"
     ]
    }
   ],
   "source": [
    "def openAI_service_generate_answer(query, rephrased_query, ai_skill_response):\n",
    "    context = get_context_to_answer_with_llm(query, rephrased_query, ai_skill_response)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id='gpt-4-32k', \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt_final_answer },\n",
    "            {\"role\": \"user\", \"content\": f\"Use the information provided in the context headers and rows: {context} and write a descriptive report assessing all the table information, then concluding with the answer to the user query.\" },\n",
    "        ],\n",
    "        temperature=0)\n",
    "\n",
    "    return response\n",
    "\n",
    "response = openAI_service_generate_answer(query, questions, ai_skill_response)\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cace625-77f6-4675-acb3-a67e4034a40b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Now that you have a clear understanding of how the framework operates, you can apply it to additional examples. This will help you see how the framework handles various scenarios and further clarify its functionality. You can call the `openAI_service_multiple_questions` function again to generate multiple related questions through rephrasing the main query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8670436-8eff-4948-8388-1be7c62f5593",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:45:22.1574553Z",
       "execution_start_time": "2024-09-16T15:44:45.3561489Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "16fe5d77-3225-4213-8bbf-8d7a386b4675",
       "queued_time": "2024-09-16T15:37:46.841549Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 19,
       "statement_ids": [
        19
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 19, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the unique product pairs that are most frequently purchased together in 2013?\n",
      "Response: In 2013, the most frequently purchased product pair was the 'Water Bottle - 30 oz.' and the 'Mountain Bottle Cage', with a purchase frequency of 1626. This was closely followed by the 'Water Bottle - 30 oz.' and the 'Road Bottle Cage', which was purchased together 1507 times. The third most common product pair was the 'Mountain Tire Tube' and the 'HL Mountain Tire', with a purchase count of 919. The 'Touring Tire Tube' and 'Touring Tire' were also frequently bought together, with a purchase frequency of 760. Lastly, the 'Patch Kit/8 Patches' and 'Mountain Tire Tube' were purchased together 739 times.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the unique product pairs that are most frequently purchased together in 2013?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "response = openAI_service_multiple_questions(query)\n",
    "answer = response.choices[0].message.content\n",
    "# print(f\"{answer}\")\n",
    "questions = answer.split(\"\\n\")\n",
    "questions.append(query)\n",
    "# print(questions)\n",
    "\n",
    "ai_skill_response = []\n",
    "ai_skill_sql = []\n",
    "for question in questions:\n",
    "    response = aiSkill(notes, question, aiskill_url)\n",
    "    ai_skill_response.append(f\"headers: {response['ResultHeaders']}, rows: {response['ResultRows']}\")\n",
    "    ai_skill_sql.append(response['executedSQL'])\n",
    "\n",
    "response = openAI_service_generate_answer(query, questions, ai_skill_response)\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"Response: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e42843-4b6a-4286-b8e6-3674b9bb366e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-09-16T15:45:45.3336931Z",
       "execution_start_time": "2024-09-16T15:45:22.5571623Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "1af4aa8e-6a44-4b7b-a2bd-44eeb2fe4a70",
       "queued_time": "2024-09-16T15:37:53.909483Z",
       "session_id": "41947b06-61e4-4d32-b0a9-dc833847a498",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 20,
       "statement_ids": [
        20
       ]
      },
      "text/plain": [
       "StatementMeta(, 41947b06-61e4-4d32-b0a9-dc833847a498, 20, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which promotion had the highest sales of products in terms of sales volume in 2013?\n",
      "Response: The top three promotions that had the highest sales of products in terms of sales volume in 2013 were the 'Volume Discount 11 to 14' with 1747 units sold, followed by the 'Touring-3000 Promotion' with 20 units sold, and the 'Touring-1000 Promotion' with 13 units sold. \n",
      "\n",
      "In 2012, the promotion that had the highest sales of products in terms of sales volume was the 'Volume Discount 11 to 14' with 367 units sold. \n",
      "\n",
      "When considering all years, the promotion that had the highest sales of products in terms of sales volume was the 'Volume Discount 11 to 14'. \n",
      "\n",
      "However, in 2013, the promotion that had the highest sales of products in terms of sales volume was the 'No Discount' promotion. This indicates that despite the success of the 'Volume Discount 11 to 14' promotion in previous years and overall, customers in 2013 were more inclined to purchase products without any promotional discounts.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which promotion had the highest sales of products in terms of sales volume in 2013?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "response = openAI_service_multiple_questions(query)\n",
    "answer = response.choices[0].message.content\n",
    "# print(f\"{answer}\")\n",
    "questions = answer.split(\"\\n\")\n",
    "questions.append(query)\n",
    "# print(questions)\n",
    "\n",
    "ai_skill_response = []\n",
    "ai_skill_sql = []\n",
    "for question in questions:\n",
    "    response = aiSkill(notes, question, aiskill_url)\n",
    "    ai_skill_response.append(f\"headers: {response['ResultHeaders']}, rows: {response['ResultRows']}\")\n",
    "    ai_skill_sql.append(response['executedSQL'])\n",
    "\n",
    "response = openAI_service_generate_answer(query, questions, ai_skill_response)\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"Response: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a53bf4-4db1-468e-8b37-c93f7fdad715",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Conclusion\n",
    "\n",
    "By following the steps outlined in this notebook, you can now create a powerful, customized AI Skill that provides comprehensive and contextually rich responses to your queries. Integrating AI Skill with LLMs allows for deeper insights by generating additional relevant questions and offering more detailed answers. This process enhances decision-making and provides users with a more enriched, data-driven experience using Microsoft Fabric."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
